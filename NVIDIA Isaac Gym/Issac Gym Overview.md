Traditional RL conducts numerous simulation and saves to RAM prior to uploading to GPU to train policy DNN. Using data uploaded to GPU, the policy network is updated to conduct simulations. This method causes inefficient data transfer and bottleneck effect of GPU resulting time-consuming computation. On the other hand, Issac Gym takes advantage of GPU computation which eliminates data transfer between RAM and GPU. 