## CS224n: Natural Language Processing with Deep Learning
## Problem Definition
This tutorial includes comprehensive lectures of natural language processing (NLP) using RNN, GRUs, and LSTM networks. NLP models aim to compute the probability of occurrence of a sequence of words to perform tasks such as speech recognition. The author introduces how languages models predict the likelihood of word sequences from utilizing historical data to inform future predictions.
## Summary of the methodology presented: algorithm, input-output
RNNs, GRUs, and LSTMs are applied to NLP tasks such as text generation, sentiment analysis, language translation, and speech recognition. These models capture long-range dependencies within the text

## Applicability / Problems solved

## Assumptions and limitations
