## MUTEX: Learning Unified Policies from Multimodal Task Specifications

## Problem Definition
Humans use different modalities such as speech, text, images, videos, etc. to effectively communicate, and the author addresses the challenge of developing policies that can reason about multimodal task specifications for diverse manipulation tasks. Each task is defined in a single modality that changes from task to task, leveraging the strengths of different modalities like goal descriptions and step-by-step video demonstrations to improve the modelâ€™s ability to execute tasks specified in different modalities

## Why the state-of-the-art is not enough for this? Why does it fail?

## What is the clever idea of this paper?

## How the idea is implemented
The idea is implemented through a two-stage training procedure that includes Mask Modeling and Cross-Modal Matching, combined with a behavior cloning objective for policy learning to foster cross-modal interactions.


##  How is success proved and measured?

