# Model-based and Model-free RL for Robot Control
## Problem Definition
Dynamic programming suffers from practical challenges such as the curse of dimensionality and performance in unknown environments. Therefore, the author introduces reinforcement learning, which can solve a more general problem optimally within an unknown environment. 

## Summary of the methodology presented: algorithm, input-output
RL includes a system with its state and control input for the system, and the environment has a reward function which defines the reward associated with every state and control. The RL algorithm aims to accumulate the highest possible reward. Model-based RL uses am explicit  model of the environment's dynamics, while model-free RL solely learns by interacting with the environment with reward.

## Applicability / Problems solved


## Assumptions and limitations
