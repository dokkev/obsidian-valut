CS237B Lecture 12: Imitation Learning

## Problem Definition
While it assumes that the reward function is known in robot learning, Reinforcement Learning suffer from setting appropriate reward function and getting potentially sparse reward. This results in the learning process expensive in amount of data n and time needed while exploring with sub-optimal policy.

## Summary of the methodology presented: algorithm, input-output
The author introduces two classical imitation learning, which are behavior cloning (BC) and DAgger, and he shows approaches for learning the reward function referred as Inverse Reinforcement Learning (IRL).  BC takes an expert's demonstration as input and outputs a policy which replicates the demonstration. DAgger iteratively collects 

## Applicability / Problems solved


## Assumptions and limitations

