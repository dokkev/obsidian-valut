LLM is not grounded in reality (lack of connection to the real context)

## SayCan
