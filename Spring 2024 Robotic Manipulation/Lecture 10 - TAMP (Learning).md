LLM is not grounded in reality (lack of connection to the real context)

## SayCan
Task grounding (say) → LLM (find a cleaner, find a sponge...) -> Value Functions ← world grounding (Can)

### Related work
- LLM-based planning without grounding
- Fine-Tune LLM to Ground
- Learning-based Symbolic TAMP